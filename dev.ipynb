{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile, loadmat\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import tensorboardX\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # scipy throws future warnings on fft (known bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationDatasetTrain(Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "        iden_split_path = os.path.join(path, 'iden_split.txt')\n",
    "        split = pd.read_table(iden_split_path, sep=' ', header=None, names=['phase', 'path'])\n",
    "        split['label'] = split['path'].apply(lambda x: int(x.split('/')[0].replace('id1', '')) - 1)\n",
    "        \n",
    "        # make train/test id split (in paths class id numbering starts with 1)\n",
    "        fullid_arr = np.arange(1251) # 1--1251\n",
    "        testid_arr = np.arange(269, 309) # 270--309\n",
    "        trainid_arr = np.setdiff1d(fullid_arr, testid_arr) # 1--1251 \\ 270--309\n",
    "        # subsetting ids for training\n",
    "        mask = split['label'].isin(trainid_arr)\n",
    "        self.dataset = split['path'][mask].reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # path\n",
    "        track_path = self.dataset[idx]\n",
    "        audio_path = os.path.join(self.path, 'audio', track_path)\n",
    "\n",
    "        # read .wav\n",
    "        rate, samples = wavfile.read(audio_path)\n",
    "        # extract label from path like id10003/L9_sh8msGV59/00001.txt\n",
    "        # subtracting 1 because PyTorch assumes that C_i in [0, 1251-1]\n",
    "        label = int(track_path.split('/')[0].replace('id1', '')) - 1\n",
    "\n",
    "        ## parameters\n",
    "        window = 'hamming'\n",
    "        # window width and step size\n",
    "        Tw = 25 # ms\n",
    "        Ts = 10 # ms\n",
    "        # frame duration (samples)\n",
    "        Nw = int(rate * Tw * 1e-3)\n",
    "        Ns = int(rate * (Tw - Ts) * 1e-3)\n",
    "        # overlapped duration (samples)\n",
    "        # 2 ** to the next pow of 2 of (Nw - 1)\n",
    "        nfft = 2 ** (Nw - 1).bit_length()\n",
    "        pre_emphasis = 0.97\n",
    "        \n",
    "        # preemphasis filter\n",
    "        samples = np.append(samples[0], samples[1:] - pre_emphasis * samples[:-1])\n",
    "        \n",
    "        # removes DC component of the signal and add a small dither\n",
    "        samples = signal.lfilter([1, -1], [1, -0.99], samples)\n",
    "        dither = np.random.uniform(-1, 1, samples.shape)\n",
    "        spow = np.std(samples)\n",
    "        samples = samples + 1e-6 * spow * dither\n",
    "        \n",
    "        # segment selection\n",
    "        segment_len = 3 # sec\n",
    "        upper_bound = len(samples) - segment_len * rate\n",
    "        start = np.random.randint(0, upper_bound)\n",
    "        end = start + segment_len * rate\n",
    "        samples = samples[start:end]\n",
    "        \n",
    "        # spectogram\n",
    "        _, _, spec = signal.spectrogram(samples, rate, window, Nw, Ns, nfft, \n",
    "                                        mode='magnitude', return_onesided=False)\n",
    "        \n",
    "        # just multiplying it by 1600 makes spectrograms in the paper and here \"the same\"\n",
    "        spec *= rate / 10\n",
    "        \n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "\n",
    "        return label, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2]) tensor([[[[ 1.0483e+00,  2.1217e+00,  5.2499e-01,  ..., -4.4210e-01,\n",
      "           -7.2653e-01, -2.8890e-01],\n",
      "          [ 9.8662e-01,  1.7658e+00,  6.9059e-01,  ..., -5.2170e-01,\n",
      "           -5.1605e-01, -7.1154e-01],\n",
      "          [-4.2422e-01,  6.6823e-01, -4.6894e-01,  ..., -1.0900e+00,\n",
      "            5.8806e-01,  1.5031e-01],\n",
      "          ...,\n",
      "          [ 9.4948e-01,  1.9095e-01,  1.2764e+00,  ..., -3.2930e-01,\n",
      "            3.7034e-01, -2.4474e-01],\n",
      "          [-4.2422e-01,  6.6823e-01, -4.6894e-01,  ..., -1.0900e+00,\n",
      "            5.8806e-01,  1.5031e-01],\n",
      "          [ 9.8662e-01,  1.7658e+00,  6.9059e-01,  ..., -5.2170e-01,\n",
      "           -5.1605e-01, -7.1154e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4684e-01,  1.6470e+00,  2.6858e+00,  ...,  1.2834e+00,\n",
      "           -6.7492e-01, -5.1781e-01],\n",
      "          [-2.5908e-01,  1.4524e+00,  2.8419e+00,  ...,  1.3552e+00,\n",
      "           -6.7125e-01, -6.3792e-01],\n",
      "          [-1.5094e+00,  6.3116e-03, -3.7809e-01,  ...,  1.5188e+00,\n",
      "           -5.7417e-01,  2.9725e-01],\n",
      "          ...,\n",
      "          [ 4.6846e-01,  1.1612e+00,  7.4977e-01,  ...,  5.3022e-01,\n",
      "            2.3378e-01,  1.2464e-01],\n",
      "          [-1.5094e+00,  6.3116e-03, -3.7809e-01,  ...,  1.5188e+00,\n",
      "           -5.7417e-01,  2.9725e-01],\n",
      "          [-2.5908e-01,  1.4524e+00,  2.8419e+00,  ...,  1.3552e+00,\n",
      "           -6.7125e-01, -6.3792e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7884e-01, -1.9896e-01, -7.4938e-01,  ..., -4.6140e-02,\n",
      "            8.5029e-01,  2.8584e+00],\n",
      "          [-4.9177e-01,  1.7976e-01, -9.4831e-01,  ..., -8.5810e-02,\n",
      "            6.7005e-01,  2.7361e+00],\n",
      "          [-1.0796e+00, -1.2648e+00, -1.3199e-01,  ..., -9.2730e-01,\n",
      "           -1.1737e-01, -3.1353e-01],\n",
      "          ...,\n",
      "          [-6.8740e-01, -1.1395e+00, -1.2423e+00,  ...,  1.1843e+00,\n",
      "            9.0812e-01,  4.4624e-01],\n",
      "          [-1.0796e+00, -1.2648e+00, -1.3199e-01,  ..., -9.2730e-01,\n",
      "           -1.1737e-01, -3.1353e-01],\n",
      "          [-4.9177e-01,  1.7976e-01, -9.4831e-01,  ..., -8.5810e-02,\n",
      "            6.7005e-01,  2.7361e+00]]]])\n",
      "tensor([2, 2, 2]) tensor([[[[ 5.1363e+00,  2.7576e+00, -4.5718e-01,  ..., -6.7368e-01,\n",
      "           -6.7096e-01, -6.6454e-01],\n",
      "          [ 5.2071e+00,  2.7553e+00, -3.4985e-01,  ..., -7.3262e-01,\n",
      "           -5.8508e-01, -7.2103e-01],\n",
      "          [ 8.4628e-01,  2.2346e-01, -5.3052e-01,  ..., -1.0545e-01,\n",
      "           -9.9254e-01,  3.1888e-01],\n",
      "          ...,\n",
      "          [ 7.7159e-02,  2.5689e-01, -8.5988e-01,  ..., -3.9306e-02,\n",
      "           -5.8990e-01,  1.4278e-01],\n",
      "          [ 8.4628e-01,  2.2346e-01, -5.3052e-01,  ..., -1.0545e-01,\n",
      "           -9.9254e-01,  3.1888e-01],\n",
      "          [ 5.2071e+00,  2.7553e+00, -3.4985e-01,  ..., -7.3262e-01,\n",
      "           -5.8508e-01, -7.2103e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.4498e-01, -7.2379e-01, -4.8144e-01,  ...,  2.1186e-01,\n",
      "           -2.1783e-01, -9.1080e-01],\n",
      "          [-1.3320e+00, -7.0122e-01, -9.8967e-01,  ...,  2.4241e-01,\n",
      "            2.9492e-01, -1.1623e+00],\n",
      "          [-1.1753e+00,  3.2403e-01, -9.1972e-01,  ..., -1.0168e-01,\n",
      "            1.6629e-01, -6.6758e-01],\n",
      "          ...,\n",
      "          [-8.8714e-01, -2.6357e-01, -1.4824e-01,  ..., -8.7580e-01,\n",
      "           -8.1057e-01, -8.9145e-01],\n",
      "          [-1.1753e+00,  3.2403e-01, -9.1972e-01,  ..., -1.0168e-01,\n",
      "            1.6629e-01, -6.6758e-01],\n",
      "          [-1.3320e+00, -7.0122e-01, -9.8967e-01,  ...,  2.4241e-01,\n",
      "            2.9492e-01, -1.1623e+00]]],\n",
      "\n",
      "\n",
      "        [[[-5.8710e-01, -7.1249e-01, -6.4601e-01,  ..., -7.1390e-01,\n",
      "           -7.2622e-01, -7.2658e-01],\n",
      "          [-6.2938e-01, -7.6935e-01, -6.9573e-01,  ..., -7.2820e-01,\n",
      "           -6.7336e-01, -7.3593e-01],\n",
      "          [-7.4180e-01, -5.8223e-01, -4.5848e-01,  ..., -5.9212e-01,\n",
      "           -6.9789e-01, -7.6327e-01],\n",
      "          ...,\n",
      "          [-6.1760e-01, -7.4642e-01, -6.0026e-01,  ..., -6.3383e-01,\n",
      "           -8.6319e-01, -8.4778e-01],\n",
      "          [-7.4180e-01, -5.8223e-01, -4.5848e-01,  ..., -5.9212e-01,\n",
      "           -6.9789e-01, -7.6327e-01],\n",
      "          [-6.2938e-01, -7.6935e-01, -6.9573e-01,  ..., -7.2820e-01,\n",
      "           -6.7336e-01, -7.3593e-01]]]])\n",
      "tensor([2, 2, 2]) tensor([[[[-7.6021e-01,  8.3916e-01, -9.3428e-01,  ..., -8.9152e-01,\n",
      "           -3.4691e-01, -8.6604e-01],\n",
      "          [-6.7945e-01,  8.1324e-01, -3.7354e-01,  ..., -8.4907e-01,\n",
      "           -2.4067e-01, -9.3368e-01],\n",
      "          [-8.1871e-01, -6.6142e-02,  9.4699e-01,  ...,  1.2348e+00,\n",
      "            2.7656e+00,  1.5820e+00],\n",
      "          ...,\n",
      "          [-8.6186e-01, -1.0146e+00, -5.6056e-01,  ...,  2.6383e+00,\n",
      "            2.8055e+00,  1.5520e+00],\n",
      "          [-8.1871e-01, -6.6142e-02,  9.4699e-01,  ...,  1.2348e+00,\n",
      "            2.7656e+00,  1.5820e+00],\n",
      "          [-6.7945e-01,  8.1324e-01, -3.7354e-01,  ..., -8.4907e-01,\n",
      "           -2.4067e-01, -9.3368e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.4385e-02, -3.7510e-01, -1.9943e-01,  ..., -3.7772e-01,\n",
      "            2.3348e-01,  2.0657e+00],\n",
      "          [-4.8596e-01, -6.2884e-01,  3.2546e-01,  ..., -2.1016e-01,\n",
      "            1.5520e-01,  2.0998e+00],\n",
      "          [ 3.1810e+00,  2.9084e+00,  3.1751e+00,  ...,  1.0009e+00,\n",
      "            2.2920e-01,  3.0825e+00],\n",
      "          ...,\n",
      "          [ 1.6213e+00,  1.4010e+00,  1.3457e+00,  ...,  2.2397e+00,\n",
      "            1.8976e+00,  2.2186e+00],\n",
      "          [ 3.1810e+00,  2.9084e+00,  3.1751e+00,  ...,  1.0009e+00,\n",
      "            2.2920e-01,  3.0825e+00],\n",
      "          [-4.8596e-01, -6.2884e-01,  3.2546e-01,  ..., -2.1016e-01,\n",
      "            1.5520e-01,  2.0998e+00]]],\n",
      "\n",
      "\n",
      "        [[[-4.5601e-01,  2.2105e-01,  1.6543e-01,  ...,  8.5596e-01,\n",
      "            1.4320e+00,  4.2377e-01],\n",
      "          [-5.3229e-01, -1.5637e-01,  6.3420e-02,  ...,  9.9543e-01,\n",
      "            1.7654e+00,  4.9120e-01],\n",
      "          [ 1.2855e-01,  4.6416e-01, -7.2159e-01,  ..., -1.6749e-02,\n",
      "           -6.1435e-02,  9.0669e-01],\n",
      "          ...,\n",
      "          [ 8.3570e-01,  5.0057e-01, -4.5658e-01,  ...,  1.7575e+00,\n",
      "            1.4022e+00,  1.5437e+00],\n",
      "          [ 1.2855e-01,  4.6416e-01, -7.2159e-01,  ..., -1.6749e-02,\n",
      "           -6.1435e-02,  9.0669e-01],\n",
      "          [-5.3229e-01, -1.5637e-01,  6.3420e-02,  ...,  9.9543e-01,\n",
      "            1.7654e+00,  4.9120e-01]]]])\n",
      "tensor([2, 2, 2]) tensor([[[[-3.5258e-01, -2.3865e-01, -3.4323e-01,  ...,  4.2559e+00,\n",
      "           -1.8816e-01,  1.4080e+00],\n",
      "          [-3.3861e-01, -3.2551e-01, -3.8238e-01,  ...,  4.0427e+00,\n",
      "           -3.4769e-01,  1.0267e+00],\n",
      "          [-7.6894e-01, -5.5626e-01, -3.8472e-01,  ...,  1.8737e-01,\n",
      "            1.4233e-01,  1.4684e+00],\n",
      "          ...,\n",
      "          [-7.9504e-01, -7.5633e-01, -7.5528e-01,  ...,  3.5439e-01,\n",
      "            1.1381e+00,  4.1561e-01],\n",
      "          [-7.6894e-01, -5.5626e-01, -3.8472e-01,  ...,  1.8737e-01,\n",
      "            1.4233e-01,  1.4684e+00],\n",
      "          [-3.3861e-01, -3.2551e-01, -3.8238e-01,  ...,  4.0427e+00,\n",
      "           -3.4769e-01,  1.0267e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.2440e-01, -6.1671e-01, -7.7785e-01,  ..., -4.4357e-02,\n",
      "           -5.3861e-01, -3.4010e-01],\n",
      "          [-1.8556e-01, -7.4967e-01, -3.0310e-01,  ..., -2.3007e-01,\n",
      "           -4.6614e-01, -3.7410e-01],\n",
      "          [-3.0187e-01, -9.5732e-01, -1.6056e-01,  ...,  1.4283e-01,\n",
      "           -1.3689e+00,  1.4791e+00],\n",
      "          ...,\n",
      "          [-1.2345e+00, -1.1347e+00, -9.2841e-01,  ...,  8.0931e-01,\n",
      "            6.5010e-01,  8.9458e-01],\n",
      "          [-3.0187e-01, -9.5732e-01, -1.6056e-01,  ...,  1.4283e-01,\n",
      "           -1.3689e+00,  1.4791e+00],\n",
      "          [-1.8556e-01, -7.4967e-01, -3.0310e-01,  ..., -2.3007e-01,\n",
      "           -4.6614e-01, -3.7410e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1714e-01, -5.7516e-01, -1.6376e-01,  ...,  3.3884e+00,\n",
      "            1.2557e+00,  2.7110e+00],\n",
      "          [-6.5918e-01, -4.3589e-01, -4.0129e-01,  ...,  3.5591e+00,\n",
      "           -2.5495e-01,  3.6231e+00],\n",
      "          [-1.0206e+00, -6.6508e-01, -1.0967e+00,  ..., -1.0540e+00,\n",
      "            4.7948e-01,  1.4590e+00],\n",
      "          ...,\n",
      "          [-1.0195e+00, -9.2010e-01, -1.0566e+00,  ...,  2.3006e+00,\n",
      "            9.5652e-01,  1.1080e+00],\n",
      "          [-1.0206e+00, -6.6508e-01, -1.0967e+00,  ..., -1.0540e+00,\n",
      "            4.7948e-01,  1.4590e+00],\n",
      "          [-6.5918e-01, -4.3589e-01, -4.0129e-01,  ...,  3.5591e+00,\n",
      "           -2.5495e-01,  3.6231e+00]]]])\n",
      "tensor([1]) tensor([[[[-4.9645e-01, -8.4878e-01, -7.7996e-01,  ..., -7.5936e-01,\n",
      "           -6.4380e-01, -5.1852e-01],\n",
      "          [-3.2474e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n",
      "           -5.9822e-01, -1.8844e-01],\n",
      "          [-1.9316e-01, -9.4319e-01, -5.4747e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          ...,\n",
      "          [-4.0324e-01, -1.1349e+00, -5.4324e-01,  ...,  2.9841e+00,\n",
      "            1.5011e+00,  1.4379e-02],\n",
      "          [-1.9316e-01, -9.4319e-01, -5.4747e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          [-3.2474e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           -5.9822e-01, -1.8844e-01]]]]) tensor([[[[-9.3278e-01, -9.7684e-01, -5.8083e-01,  ...,  9.5456e-02,\n",
      "            3.8308e+00, -9.7233e-02],\n",
      "          [-9.4413e-01, -8.3841e-01, -5.6500e-01,  ..., -3.2354e-01,\n",
      "            3.0884e+00,  1.4388e-01],\n",
      "          [-1.0189e+00, -2.2917e-01, -4.3586e-01,  ...,  1.0657e+00,\n",
      "           -5.8873e-01,  5.7299e-01],\n",
      "          ...,\n",
      "          [ 2.1197e-01,  2.8076e-01, -3.5094e-01,  ..., -3.2975e-01,\n",
      "            6.5908e-01, -9.2398e-01],\n",
      "          [-1.0189e+00, -2.2917e-01, -4.3586e-01,  ...,  1.0657e+00,\n",
      "           -5.8873e-01,  5.7299e-01],\n",
      "          [-9.4413e-01, -8.3841e-01, -5.6500e-01,  ..., -3.2354e-01,\n",
      "            3.0884e+00,  1.4388e-01]]]])\n",
      "tensor([0]) tensor([[[[-4.9645e-01, -8.4878e-01, -7.7996e-01,  ..., -7.5936e-01,\n",
      "           -6.4380e-01, -5.1852e-01],\n",
      "          [-3.2474e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n",
      "           -5.9822e-01, -1.8844e-01],\n",
      "          [-1.9315e-01, -9.4318e-01, -5.4747e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          ...,\n",
      "          [-4.0323e-01, -1.1349e+00, -5.4324e-01,  ...,  2.9841e+00,\n",
      "            1.5011e+00,  1.4373e-02],\n",
      "          [-1.9315e-01, -9.4318e-01, -5.4747e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          [-3.2474e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n",
      "           -5.9822e-01, -1.8844e-01]]]]) tensor([[[[-4.1648e-01, -2.8491e-01, -2.4050e-01,  ...,  7.9402e+00,\n",
      "            2.4475e+00,  1.8127e+00],\n",
      "          [-4.0044e-01, -2.9408e-01, -2.1300e-01,  ...,  8.0148e+00,\n",
      "            2.1457e+00,  2.0184e+00],\n",
      "          [-4.0556e-01, -6.7025e-01, -6.1877e-01,  ...,  2.1574e+00,\n",
      "            1.2801e+00,  2.0832e+00],\n",
      "          ...,\n",
      "          [-7.5571e-01, -8.6189e-01, -8.6047e-01,  ...,  2.1114e+00,\n",
      "            1.4526e+00,  1.6800e+00],\n",
      "          [-4.0556e-01, -6.7025e-01, -6.1877e-01,  ...,  2.1574e+00,\n",
      "            1.2801e+00,  2.0832e+00],\n",
      "          [-4.0044e-01, -2.9408e-01, -2.1300e-01,  ...,  8.0148e+00,\n",
      "            2.1457e+00,  2.0184e+00]]]])\n",
      "tensor([1]) tensor([[[[-4.9645e-01, -8.4878e-01, -7.7996e-01,  ..., -7.5935e-01,\n",
      "           -6.4380e-01, -5.1852e-01],\n",
      "          [-3.2475e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n",
      "           -5.9822e-01, -1.8844e-01],\n",
      "          [-1.9317e-01, -9.4319e-01, -5.4746e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          ...,\n",
      "          [-4.0324e-01, -1.1349e+00, -5.4323e-01,  ...,  2.9841e+00,\n",
      "            1.5011e+00,  1.4376e-02],\n",
      "          [-1.9317e-01, -9.4319e-01, -5.4746e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          [-3.2475e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n",
      "           -5.9822e-01, -1.8844e-01]]]]) tensor([[[[ 1.3080e+00, -3.1605e-01,  5.8211e-01,  ...,  2.5189e+00,\n",
      "            6.1295e-01, -3.1160e-01],\n",
      "          [ 1.0402e+00, -4.0776e-01,  6.2825e-01,  ...,  2.6239e+00,\n",
      "            6.1968e-01, -2.3944e-01],\n",
      "          [ 2.3650e-01, -1.1586e-01, -3.3026e-01,  ...,  1.1748e+00,\n",
      "            6.4588e-01, -2.0492e-01],\n",
      "          ...,\n",
      "          [-3.3392e-01, -6.5703e-01, -4.8141e-01,  ..., -6.0594e-01,\n",
      "           -5.1074e-02,  3.6392e-01],\n",
      "          [ 2.3650e-01, -1.1586e-01, -3.3026e-01,  ...,  1.1748e+00,\n",
      "            6.4588e-01, -2.0492e-01],\n",
      "          [ 1.0402e+00, -4.0776e-01,  6.2825e-01,  ...,  2.6239e+00,\n",
      "            6.1968e-01, -2.3944e-01]]]])\n",
      "tensor([0]) tensor([[[[-4.9645e-01, -8.4878e-01, -7.7996e-01,  ..., -7.5935e-01,\n",
      "           -6.4380e-01, -5.1852e-01],\n",
      "          [-3.2474e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n",
      "           -5.9822e-01, -1.8844e-01],\n",
      "          [-1.9316e-01, -9.4319e-01, -5.4747e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          ...,\n",
      "          [-4.0323e-01, -1.1349e+00, -5.4324e-01,  ...,  2.9841e+00,\n",
      "            1.5011e+00,  1.4370e-02],\n",
      "          [-1.9316e-01, -9.4319e-01, -5.4747e-01,  ...,  1.0880e+00,\n",
      "            3.9407e-01,  5.1536e-01],\n",
      "          [-3.2474e-01, -8.6533e-01, -7.4932e-01,  ..., -2.1795e-01,\n",
      "           -5.9822e-01, -1.8844e-01]]]]) tensor([[[[-5.2221e-01, -5.0547e-01, -4.7795e-01,  ...,  4.4192e-01,\n",
      "           -8.7533e-01, -8.4317e-01],\n",
      "          [-5.5457e-01, -4.0742e-01, -6.1063e-01,  ...,  5.5814e-01,\n",
      "           -4.6303e-01, -5.3880e-01],\n",
      "          [ 2.4913e-01,  3.6879e-01, -4.4694e-01,  ...,  3.8762e-01,\n",
      "           -3.4620e-01, -1.2253e-01],\n",
      "          ...,\n",
      "          [ 4.9393e-01, -5.0659e-02, -8.5281e-01,  ...,  1.3228e+00,\n",
      "            6.8603e-01,  6.5156e-01],\n",
      "          [ 2.4913e-01,  3.6879e-01, -4.4694e-01,  ...,  3.8762e-01,\n",
      "           -3.4620e-01, -1.2253e-01],\n",
      "          [-5.5457e-01, -4.0742e-01, -6.1063e-01,  ...,  5.5814e-01,\n",
      "           -4.6303e-01, -5.3880e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "class VerificationDatasetTest(Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        veri_split_path = os.path.join(path, 'veri_test.txt')\n",
    "        self.dataset = pd.read_table(veri_split_path, sep=' ', header=None, \n",
    "                                     names=['label', 'voice1', 'voice2'])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # path\n",
    "        label, voice1_path, voice2_path = self.dataset.iloc[idx]\n",
    "        voice1_path = os.path.join(self.path, 'audio', voice1_path)\n",
    "        voice2_path = os.path.join(self.path, 'audio', voice2_path)\n",
    "\n",
    "        # read .wav\n",
    "        rate, voice1 = wavfile.read(voice1_path)\n",
    "        rate, voice2 = wavfile.read(voice2_path)\n",
    "\n",
    "        ## parameters\n",
    "        window = 'hamming'\n",
    "        # window width and step size\n",
    "        Tw = 25 # ms\n",
    "        Ts = 10 # ms\n",
    "        # frame duration (samples)\n",
    "        Nw = int(rate * Tw * 1e-3)\n",
    "        Ns = int(rate * (Tw - Ts) * 1e-3)\n",
    "        # overlapped duration (samples)\n",
    "        # 2 ** to the next pow of 2 of (Nw - 1)\n",
    "        nfft = 2 ** (Nw - 1).bit_length()\n",
    "        pre_emphasis = 0.97\n",
    "        \n",
    "        # preemphasis filter\n",
    "        voice1 = np.append(voice1[0], voice1[1:] - pre_emphasis * voice1[:-1])\n",
    "        voice2 = np.append(voice2[0], voice2[1:] - pre_emphasis * voice2[:-1])\n",
    "        \n",
    "        \n",
    "        # removes DC component of the signal and add a small dither\n",
    "        voice1 = signal.lfilter([1, -1], [1, -0.99], voice1)\n",
    "        voice2 = signal.lfilter([1, -1], [1, -0.99], voice2)\n",
    "        dither1 = np.random.uniform(-1, 1, voice1.shape)\n",
    "        dither2 = np.random.uniform(-1, 1, voice2.shape)\n",
    "        spow1 = np.std(voice1)\n",
    "        spow2 = np.std(voice2)\n",
    "        voice1 = voice1 + 1e-6 * spow1 * dither1\n",
    "        voice2 = voice2 + 1e-6 * spow2 * dither2\n",
    "        \n",
    "        # spectogram\n",
    "        _, _, spec1 = signal.spectrogram(voice1, rate, window, Nw, Ns, nfft, \n",
    "                                         mode='magnitude', return_onesided=False)\n",
    "        _, _, spec2 = signal.spectrogram(voice2, rate, window, Nw, Ns, nfft, \n",
    "                                         mode='magnitude', return_onesided=False)\n",
    "        \n",
    "        # just multiplying it by 1600 makes spectrograms in the paper and here \"the same\"\n",
    "        spec1 *= rate / 10\n",
    "        spec2 *= rate / 10\n",
    "        \n",
    "        if self.transform:\n",
    "            spec1 = self.transform(spec1)\n",
    "            spec2 = self.transform(spec2)\n",
    "\n",
    "        return label, spec1, spec2\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalizes voice spectrogram (mean-varience)\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        \n",
    "        # (Freq, Time)\n",
    "        # mean-variance normalization for every spectrogram (not batch-wise)\n",
    "        mu = spec.mean(axis=1).reshape(512, 1)\n",
    "        sigma = spec.std(axis=1).reshape(512, 1)\n",
    "        spec = (spec - mu) / sigma\n",
    "\n",
    "        return spec\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert spectogram to Tensor.\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        F, T = spec.shape\n",
    "        \n",
    "        # now specs are of size (Freq, Time) and 2D but has to be 3D (channel dim)\n",
    "        spec = spec.reshape(1, F, T)\n",
    "        \n",
    "        # make the ndarray to be of a proper type (was float64)\n",
    "        spec = spec.astype(np.float32)\n",
    "        \n",
    "        return torch.from_numpy(spec)\n",
    "\n",
    "DATASET_PATH = '/home/nvme/data/vc1/'\n",
    "\n",
    "transforms = Compose([\n",
    "    Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "trainset = VerificationDatasetTrain(DATASET_PATH, transform=transforms)\n",
    "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=3)\n",
    "\n",
    "testset = VerificationDatasetTest(DATASET_PATH, transform=transforms)\n",
    "testsetloader = torch.utils.data.DataLoader(testset, batch_size=1)\n",
    "\n",
    "for i, a in enumerate(trainsetloader, 0):\n",
    "    labels, specs = a\n",
    "    print(labels, specs)\n",
    "    if i > 2:\n",
    "        break\n",
    "\n",
    "for i, (label, spec1, spec2) in enumerate(testsetloader, 0):\n",
    "    print(label, spec1, spec2)\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
