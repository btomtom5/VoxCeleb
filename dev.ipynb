{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "# from sklearn.metrics import \n",
    "\n",
    "import tensorboardX\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # test\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        top5_accuracy = 0\n",
    "        top1_accuracy = 0\n",
    "        \n",
    "        for iter_num, (label, spec) in tqdm(enumerate(testsetloader)):\n",
    "            optimizer.zero_grad()\n",
    "            label, spec = label.to(DEVICE), spec.to(DEVICE)\n",
    "            probs = net(spec)\n",
    "            \n",
    "            # calculate Top-5 and Top-1 accuracy\n",
    "            pred_top5 = probs.topk(5)[1].view(5)\n",
    "            \n",
    "            if label in pred_top5:\n",
    "                # increment top-5 accuracy\n",
    "                top5_accuracy += 1\n",
    "                \n",
    "                if label == pred_top5[0]:\n",
    "                    # increment top-1 accuracy\n",
    "                    top1_accuracy += 1\n",
    "        \n",
    "        top5_accuracy /= len(testsetloader)\n",
    "        top1_accuracy /= len(testsetloader)\n",
    "        \n",
    "        TBoard.add_scalar('Metrics/test_top5', top5_accuracy, epoch_num)\n",
    "        TBoard.add_scalar('Metrics/test_top1', top1_accuracy, epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4554, 0.7116, 0.3623, 0.6033, 0.4377, 0.2030, 0.6980]])\n",
      "tensor([1])\n",
      "tensor([[1, 6, 3, 0, 4]])\n",
      "True\n",
      "True\n",
      "tensor([1], dtype=torch.uint8)\n",
      "it works\n"
     ]
    }
   ],
   "source": [
    "C = 7 # 1251\n",
    "SIZE = (1, C)\n",
    "probs = torch.rand(SIZE) # net(spec)\n",
    "label = torch.randint(C, size=(1,)).type(torch.LongTensor)\n",
    "pred_top5 = probs.topk(5)[1]\n",
    "pred_top1 = probs.topk(1)[1]\n",
    "print(probs)\n",
    "print(label)\n",
    "print(pred_top5)\n",
    "print(label in pred_top5.view(5))\n",
    "print(label in pred_top1.view(1))\n",
    "print(label == pred_top5.view(5)[0])\n",
    "if label == pred_top5.view(5)[0]:\n",
    "    print('it works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
