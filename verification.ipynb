{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import tensorboardX\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # scipy throws future warnings on fft (known bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2spectrogram(path, segment_len=3, window='hamming', Tw=25, Ts=10, \n",
    "                    pre_emphasis=0.97, alpha=0.99, return_onesided=False):\n",
    "    # read .wav file\n",
    "    rate, samples = wavfile.read(path)\n",
    "    \n",
    "    ## parameters\n",
    "    # frame duration (samples)\n",
    "    Nw = int(rate * Tw * 1e-3)\n",
    "    Ns = int(rate * (Tw - Ts) * 1e-3)\n",
    "    # overlapped duration (samples)\n",
    "    # 2 ** to the next pow of 2 of (Nw - 1)\n",
    "    nfft = 2 ** (Nw - 1).bit_length()\n",
    "\n",
    "    # preemphasis filter\n",
    "    samples = np.append(samples[0], samples[1:] - pre_emphasis * samples[:-1])\n",
    "\n",
    "    # removes DC component of the signal and add a small dither\n",
    "    samples = signal.lfilter([1, -1], [1, -alpha], samples)\n",
    "    dither = np.random.uniform(-1, 1, samples.shape)\n",
    "    spow = np.std(samples)\n",
    "    samples = samples + 1e-6 * spow * dither\n",
    "\n",
    "    # segment selection\n",
    "    upper_bound = len(samples) - segment_len * rate\n",
    "    start = np.random.randint(0, upper_bound)\n",
    "    end = start + segment_len * rate\n",
    "    samples = samples[start:end]\n",
    "\n",
    "    # spectogram\n",
    "    _, _, spec = signal.spectrogram(samples, rate, window, Nw, Ns, nfft, \n",
    "                                    mode='magnitude', return_onesided=return_onesided)\n",
    "\n",
    "    # just multiplying it by 1600 makes spectrograms in the paper and here \"the same\"\n",
    "    spec *= rate / 10\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentificationDatasetTrain(Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "        iden_split_path = os.path.join(path, 'iden_split.txt')\n",
    "        split = pd.read_table(iden_split_path, sep=' ', header=None, names=['phase', 'path'])\n",
    "        split['label'] = split['path'].apply(lambda x: int(x.split('/')[0].replace('id1', '')) - 1)\n",
    "        \n",
    "        # make train/test id split (in paths class id numbering starts with 1)\n",
    "        fullid_arr = np.arange(1251) # 1--1251\n",
    "        testid_arr = np.arange(269, 309) # 270--309\n",
    "        trainid_arr = np.setdiff1d(fullid_arr, testid_arr) # 1--1251 \\ 270--309\n",
    "        # subsetting ids for training\n",
    "        mask = split['label'].isin(trainid_arr)\n",
    "        self.dataset = split['path'][mask].reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # path\n",
    "        track_path = self.dataset[idx]\n",
    "        audio_path = os.path.join(self.path, 'audio', track_path)\n",
    "        \n",
    "        # extract label from path like id10003/L9_sh8msGV59/00001.txt\n",
    "        # subtracting 1 because PyTorch assumes that C_i in [0, 1251-1]\n",
    "        label = int(track_path.split('/')[0].replace('id1', '')) - 1\n",
    "        # PyTorch complains if label > num_classes. For ex, num_classes=1211\n",
    "        # label is 1250. train labels \\in [0, ..., 268, 309, ..., 1250]. (269 + 942 = 1211)\n",
    "        # therefore, we subtract 40 (# of test classes) from a label => label \\in [0, 1211]\n",
    "        if label >= 309:\n",
    "            label -= 40\n",
    "        \n",
    "        # make a spectrogram from a .wavfile\n",
    "        spec = wav2spectrogram(audio_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            spec = self.transform(spec)\n",
    "\n",
    "        return label, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"Normalizes voice spectrogram (mean-varience)\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        \n",
    "        # (Freq, Time)\n",
    "        # mean-variance normalization for every spectrogram (not batch-wise)\n",
    "        mu = spec.mean(axis=1).reshape(512, 1)\n",
    "        sigma = spec.std(axis=1).reshape(512, 1)\n",
    "        spec = (spec - mu) / sigma\n",
    "\n",
    "        return spec\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert spectogram to Tensor.\"\"\"\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        F, T = spec.shape\n",
    "        \n",
    "        # now specs are of size (Freq, Time) and 2D but has to be 3D (channel dim)\n",
    "        spec = spec.reshape(1, F, T)\n",
    "        \n",
    "        # make the ndarray to be of a proper type (was float64)\n",
    "        spec = spec.astype(np.float32)\n",
    "        \n",
    "        return torch.from_numpy(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VoiceNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=7, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=96)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=256)\n",
    "        self.bn6 = nn.BatchNorm2d(num_features=4096)\n",
    "        self.bn7 = nn.BatchNorm1d(num_features=1024)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.mpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.mpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.mpool5 = nn.MaxPool2d(kernel_size=(5, 3), stride=(3, 2))\n",
    "        \n",
    "        # Conv2d with weights of size (H, 1) is identical to FC with H weights\n",
    "        self.fc6 = nn.Conv2d(in_channels=256, out_channels=4096, kernel_size=(9, 1))\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=1024)\n",
    "        self.fc8 = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "        \n",
    "    def forward_once(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.mpool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.mpool2(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.mpool5(x)\n",
    "        x = self.relu(self.bn6(self.fc6(x)))\n",
    "        \n",
    "        _, _, _, W = x.size()\n",
    "        self.apool6 = nn.AvgPool2d(kernel_size=(1, W))\n",
    "        x = self.apool6(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.relu(self.bn7(self.fc7(x)))\n",
    "            x = self.fc8(x)\n",
    "        \n",
    "        # we use the fc7 output for Hard Negative Mining (inference)\n",
    "        else:\n",
    "            x = self.fc7(x)\n",
    "            x = F.normalize(x)\n",
    "        \n",
    "        # during training, there's no need for SoftMax because CELoss calculates it\n",
    "        return x\n",
    "    \n",
    "    # phase: [training_iden, inference_negative_mining, training_siamese, verif_test]\n",
    "    def forward(self, voice1, voice2=None, phase='train_iden'):\n",
    "        if phase in ['train_iden', 'eval_mining']:\n",
    "            return self.forward_once(voice1)\n",
    "        \n",
    "        elif phase in ['train_veri', 'eval_veri']:\n",
    "            voice1 = self.forward_once(voice1)\n",
    "            voice2 = self.forward_once(voice2)\n",
    "            return voice1, voice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/nvme/data/vc1/'\n",
    "LOG_PATH = '/home/nvme/logs/VoxCeleb/_grad_test_{}'.format(time.time()) ## HERE\n",
    "EPOCH_NUM = 30\n",
    "\n",
    "# in shared code B = 100 but PyTorch throws CUDA out of memory at B = 97 \n",
    "# though B=96 takes only 90.6% of the GPU Mem (bug?):\n",
    "# https://discuss.pytorch.org/t/lesser-memory-consumption-with-a-larger-batch-in-multi-gpu-setup/29087\n",
    "# B = 96\n",
    "# but when \n",
    "torch.backends.cudnn.deterministic = True\n",
    "# I can set B = 100\n",
    "B = 100\n",
    "\n",
    "WEIGHT_DECAY = 5e-4\n",
    "LR_INIT = 1e-2\n",
    "LR_LAST = 1e-4\n",
    "# lr scheduler parameter\n",
    "gamma = 10 ** (np.log10(LR_LAST / LR_INIT) / (EPOCH_NUM - 1))\n",
    "MOMENTUM = 0.9\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_WORKERS = 4\n",
    "TBoard = tensorboardX.SummaryWriter(log_dir=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = VoiceNet(num_classes=1211)\n",
    "# net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms = Compose([\n",
    "#     Normalize(),\n",
    "#     ToTensor()\n",
    "# ])\n",
    "\n",
    "# trainset = IdentificationDatasetTrain(DATASET_PATH, transform=transforms)\n",
    "# trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=B, \n",
    "#                                              num_workers=NUM_WORKERS, shuffle=True)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), LR_INIT, MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "# lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch_num in range(EPOCH_NUM):\n",
    "#     lr_scheduler.step()\n",
    "    \n",
    "#     # train\n",
    "#     net.train()\n",
    "    \n",
    "#     for iter_num, (labels, specs) in tqdm(enumerate(trainsetloader)):\n",
    "#         optimizer.zero_grad()\n",
    "#         labels, specs = labels.to(DEVICE), specs.to(DEVICE)\n",
    "#         scores = net(specs, phase='train_iden')\n",
    "#         loss = criterion(scores, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # TBoard\n",
    "#         step_num = epoch_num * len(trainsetloader) + iter_num\n",
    "#         TBoard.add_scalar('Metrics/train_loss', loss.item(), step_num)\n",
    "#         TBoard.add_scalar('Metrics/lr', lr_scheduler.get_lr()[0], step_num)\n",
    "        \n",
    "# # when the training is finished save the model\n",
    "# torch.save(net.state_dict(), os.path.join(LOG_PATH, 'model_snapshot_{}.txt'.format(time.time())))\n",
    "# TBoard.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del specs, labels, net\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_dict = torch.load(os.path.join(LOG_PATH, 'model_snapshot_1542979501.519298.txt'))\n",
    "\n",
    "# net = VoiceNet(num_classes=1211)\n",
    "# net.to(DEVICE)\n",
    "\n",
    "# model_dict = net.state_dict()\n",
    "\n",
    "# # 1. filter out unnecessary keys\n",
    "# pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# # 2. overwrite entries in the existing state dict\n",
    "# model_dict.update(pretrained_dict) \n",
    "# # 3. load the new state dict\n",
    "# net.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_dict = torch.load(os.path.join(LOG_PATH, 'model_snapshot_1542979501.519298.txt'))\n",
    "pretrained_dict = torch.load('/home/nvme/logs/VoxCeleb/verif_class/model_snapshot_1542979501.519298.txt')\n",
    "\n",
    "net = VoiceNet(num_classes=1211)\n",
    "net.to(DEVICE)\n",
    "\n",
    "model_dict = net.state_dict()\n",
    "\n",
    "# # 1. filter out unnecessary keys\n",
    "# pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# # 2. overwrite entries in the existing state dict\n",
    "# model_dict.update(pretrained_dict) \n",
    "# # 3. load the new state dict\n",
    "# net.load_state_dict(model_dict)\n",
    "net.load_state_dict(pretrained_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationDatasetTrain(Dataset):\n",
    "    \n",
    "    def __init__(self, path, model, batch_size, device, transform=None):\n",
    "        self.path = path\n",
    "        self.model = model\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        \n",
    "        fullid_arr = np.arange(1, 1252) # 1--1251\n",
    "        testid_arr = np.arange(270, 310) # 270--309\n",
    "        trainid_arr = np.setdiff1d(fullid_arr, testid_arr) # 1--1251 \\ 270--309\n",
    "\n",
    "        # split the set of ids into `len(trainid_arr) // batch_size` subsets\n",
    "        self.splits = np.array_split(trainid_arr, len(trainid_arr) // batch_size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.splits)\n",
    "    \n",
    "    def cosine_sim_matrix(self, tensor1, tensor2):\n",
    "        B, D = tensor1.size()\n",
    "        dot = tensor2 @ tensor1.t()\n",
    "        norm1 = tensor1.norm(dim=1)\n",
    "        norm2 = tensor2.norm(dim=1).view(1, B).t()\n",
    "        dot /= norm1 * norm2\n",
    "        return dot.t()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        ## POSITIVE PART\n",
    "        ids = self.splits[idx]\n",
    "        # shuffle ids to make sure that every negative pair will consist of voices of \n",
    "        # different identities at each iteration.\n",
    "        ids = np.random.permutation(ids)\n",
    "        anchors = [0] * len(ids)\n",
    "        positives = [0] * len(ids)\n",
    "        \n",
    "        for i, id in enumerate(ids):\n",
    "            # folders have paths as follows:\n",
    "            # ids/tracks/segments\n",
    "            # for examples: id10254/7gWzIy6yIIk/00001.wav\n",
    "            # 265 -> id10265\n",
    "            full_id = 'id1{:04d}'.format(id)\n",
    "            # list all tracks for that id\n",
    "            track_list = os.listdir(os.path.join(self.path, 'audio', full_id))\n",
    "            # randomly select two tracks without replacement\n",
    "            track1, track2 = np.random.choice(track_list, 2, replace=False)\n",
    "            # select two voice tracks\n",
    "            track1_fullpath = os.path.join(self.path, 'audio', full_id, track1)\n",
    "            track2_fullpath = os.path.join(self.path, 'audio', full_id, track2)\n",
    "            # list all segments for each voice track\n",
    "            track1_segments = os.listdir(track1_fullpath)\n",
    "            track2_segments = os.listdir(track2_fullpath)\n",
    "            # randomly select two voice segments\n",
    "            track1_name = np.random.choice(track1_segments)\n",
    "            track2_name = np.random.choice(track2_segments)\n",
    "            # then construct full paths\n",
    "            voice1_path = os.path.join(track1_fullpath, track1_name)\n",
    "            voice2_path = os.path.join(track2_fullpath, track2_name)\n",
    "            # create spectrograms for selected .wav files\n",
    "            spec1 = wav2spectrogram(voice1_path)\n",
    "            spec2 = wav2spectrogram(voice2_path)\n",
    "            \n",
    "            # apply transformations\n",
    "            if self.transform:\n",
    "                spec1 = self.transform(spec1)\n",
    "                spec2 = self.transform(spec2)\n",
    "\n",
    "            # add to the list\n",
    "            anchors[i] = spec1\n",
    "            positives[i] = spec2\n",
    "        \n",
    "        # concatenate and add \"channel\" dimension\n",
    "        anchors = torch.cat(anchors).unsqueeze(1)\n",
    "        positives = torch.cat(positives).unsqueeze(1)\n",
    "        \n",
    "        # we need to keep spectrograms in memory in order to return them later\n",
    "        anchor_specs = anchors.clone()\n",
    "        positive_specs = positives.clone()\n",
    "        \n",
    "        # before feeding tensors into net, transfer them to a device (GPU)\n",
    "        anchors = anchors.to(self.device)\n",
    "        positives = positives.to(self.device)\n",
    "        \n",
    "        # calculate embeddings and make sure we switch phase back to training\n",
    "        self.model.eval()\n",
    "        anchors = self.model(anchors, phase='eval_mining') # B, 1024\n",
    "        positives = self.model(positives, phase='eval_mining') # --//---\n",
    "        self.model.train()\n",
    "        \n",
    "        # there is no need to keep tensors in GPU memory # TODO\n",
    "        anchors = anchors.cpu()\n",
    "        positives = positives.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        ## NEGATIVE PART\n",
    "        # calculate a cosine similarity matrix\n",
    "        sim_mat = self.cosine_sim_matrix(anchors, positives)\n",
    "        \n",
    "        sim_sorted, sim_sorted_idx = sim_mat.sort(dim=1)\n",
    "        # Given a sim matrix Sij, if i=j a value corresponds to a similarity between \n",
    "        # positive pairs -> we need to prevent them from getting to the negative samples\n",
    "        # First, we need to remove i=j elements.\n",
    "        B = len(ids)\n",
    "        mask = (sim_sorted_idx != torch.arange(B).repeat(1, B).view(B, B).t())\n",
    "        sim_sorted_idx_rm = sim_sorted_idx[mask].view(B, B-1)\n",
    "        \n",
    "        # HARD NEGATIVE MINING PART\n",
    "        # select the indices for appropriately hard samples\n",
    "        tau = 0.1\n",
    "        idx_threshold = round(tau * (B-2))\n",
    "        # only half of the batch size -> B // 2\n",
    "        hnm_idxs = sim_sorted_idx_rm[B // 2:, idx_threshold]\n",
    "        \n",
    "        # RANDOM PART\n",
    "        idx_threshold_rand = torch.from_numpy(np.random.uniform(size=(B, 1)) * (B-1)).long()\n",
    "        rand_idxs = torch.gather(sim_sorted_idx_rm, dim=1, index=idx_threshold_rand)[:B // 2]\n",
    "        negative_specs = positive_specs[torch.cat([rand_idxs.view(-1), hnm_idxs.view(-1)]), :]\n",
    "        \n",
    "        anchors_anchors_specs = torch.cat([anchor_specs, anchor_specs])\n",
    "        positives_negatives_specs = torch.cat([positive_specs, negative_specs])\n",
    "        labels = torch.cat([torch.ones(B), torch.zeros(B)])\n",
    "        \n",
    "        return labels, anchors_anchors_specs, positives_negatives_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationDatasetTest(Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "        test_pairs_path = os.path.join(self.path, 'veri_test.txt')\n",
    "        self.dataset = pd.read_table(test_pairs_path, sep=' ', header=None)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        label, voice1_path, voice2_path = self.dataset.iloc[idx]\n",
    "        \n",
    "        voice1_path_full = os.path.join(self.path, 'audio', voice1_path)\n",
    "        voice2_path_full = os.path.join(self.path, 'audio', voice2_path)\n",
    "        \n",
    "        spec1 = wav2spectrogram(voice1_path_full)\n",
    "        spec2 = wav2spectrogram(voice2_path_full)\n",
    "        \n",
    "        if self.transform:\n",
    "            spec1 = self.transform(spec1)\n",
    "            spec2 = self.transform(spec2)\n",
    "        \n",
    "        return label, spec1, spec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.pdist = nn.PairwiseDistance()\n",
    "        \n",
    "    def forward(self, labels, anchors, counterparts):\n",
    "        dists = self.pdist(F.normalize(anchors), F.normalize(counterparts))\n",
    "        loss = torch.mean(labels * dists ** 2 + (1 - labels) * (self.margin - dists).clamp(0) ** 2)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "net.fc8 = nn.Linear(net.fc8.in_features, 1024)\n",
    "net.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 30\n",
    "\n",
    "transforms = Compose([\n",
    "    Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# TODO: add a comment on different batch sizes\n",
    "trainset = VerificationDatasetTrain(DATASET_PATH, model=net, batch_size=B,\n",
    "                                    device=DEVICE, transform=transforms)\n",
    "trainsetloader = torch.utils.data.DataLoader(trainset, batch_size=1, num_workers=0, \n",
    "                                             shuffle=True)\n",
    "\n",
    "testset = VerificationDatasetTest(DATASET_PATH, transforms)\n",
    "testsetloader = torch.utils.data.DataLoader(testset, batch_size=1, num_workers=0)\n",
    "\n",
    "criterion = ContrastiveLoss(margin=0.6)\n",
    "optimizer = optim.SGD(net.parameters(), LR_INIT, MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "print(net.fc8.weight.requires_grad, net.conv1.weight.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024]) torch.Size([1, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.057361651211977005"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec1, spec2 = torch.rand(1, 1, 512, 298), torch.rand(1, 1, 512, 298)\n",
    "spec1, spec2 = net(spec1.to(DEVICE), spec2.to(DEVICE), phase='eval_veri')\n",
    "print(spec1.shape, spec2.shape)\n",
    "F.pairwise_distance(spec1, spec2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:00, 35.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:00, 39.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "16it [00:00, 42.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "22it [00:00, 45.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "28it [00:00, 47.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "33it [00:00, 47.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "39it [00:00, 48.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "44it [00:00, 48.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "50it [00:01, 49.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "55it [00:01, 49.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "61it [00:01, 51.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "67it [00:01, 52.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "73it [00:01, 52.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "79it [00:01, 52.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "85it [00:01, 52.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "91it [00:01, 51.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "97it [00:01, 50.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "103it [00:02, 49.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "108it [00:02, 49.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "114it [00:02, 50.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "120it [00:02, 51.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "126it [00:02, 52.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "132it [00:02, 52.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "138it [00:02, 51.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "144it [00:02, 51.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "150it [00:02, 50.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "156it [00:03, 51.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "162it [00:03, 52.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "168it [00:03, 52.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "174it [00:03, 52.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "180it [00:03, 50.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "186it [00:03, 49.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "192it [00:03, 50.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "198it [00:03, 47.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "203it [00:04, 48.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "209it [00:04, 49.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "215it [00:04, 50.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "221it [00:04, 51.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "227it [00:04, 52.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "233it [00:04, 52.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "239it [00:04, 53.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "245it [00:04, 53.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "251it [00:04, 52.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "257it [00:05, 51.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "263it [00:05, 51.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "269it [00:05, 51.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "275it [00:05, 51.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "281it [00:05, 50.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "287it [00:05, 50.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "293it [00:05, 51.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "299it [00:05, 52.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "305it [00:05, 52.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "311it [00:06, 52.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "317it [00:06, 52.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "323it [00:06, 52.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "329it [00:06, 51.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "335it [00:06, 49.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "341it [00:06, 49.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "347it [00:06, 50.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "353it [00:06, 51.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "359it [00:07, 51.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "365it [00:07, 49.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "371it [00:07, 49.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "377it [00:07, 50.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "383it [00:07, 50.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "389it [00:07, 51.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "395it [00:07, 52.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "401it [00:07, 52.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "407it [00:07, 53.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "413it [00:08, 53.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "419it [00:08, 54.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "425it [00:08, 53.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "431it [00:08, 53.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "437it [00:08, 51.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "443it [00:08, 50.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "449it [00:08, 50.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "455it [00:08, 49.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "461it [00:08, 50.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "467it [00:09, 51.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "473it [00:09, 50.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "479it [00:09, 50.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "485it [00:09, 49.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "490it [00:09, 48.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "496it [00:09, 50.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "502it [00:09, 50.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "508it [00:09, 52.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "514it [00:10, 52.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "520it [00:10, 52.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "526it [00:10, 52.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "532it [00:10, 52.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "538it [00:10, 52.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "544it [00:10, 52.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "550it [00:10, 52.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "556it [00:10, 51.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "562it [00:10, 50.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "568it [00:11, 51.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "574it [00:11, 52.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "580it [00:11, 51.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "586it [00:11, 49.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "592it [00:11, 50.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "598it [00:11, 49.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "604it [00:11, 50.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "610it [00:11, 51.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "616it [00:12, 51.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "622it [00:12, 51.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "628it [00:12, 52.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "634it [00:12, 52.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "640it [00:12, 52.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "646it [00:12, 51.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "652it [00:12, 51.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "658it [00:12, 51.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "664it [00:12, 51.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "670it [00:13, 50.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "676it [00:13, 49.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "681it [00:13, 49.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "687it [00:13, 50.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "693it [00:13, 50.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "699it [00:13, 50.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "705it [00:13, 49.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "710it [00:13, 48.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "715it [00:13, 49.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "720it [00:14, 48.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "726it [00:14, 50.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "732it [00:14, 49.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "738it [00:14, 50.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "744it [00:14, 49.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "750it [00:14, 50.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "756it [00:14, 50.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "762it [00:14, 51.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "768it [00:15, 51.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "774it [00:15, 51.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "780it [00:15, 52.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "786it [00:15, 52.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "792it [00:15, 49.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "798it [00:15, 50.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "804it [00:15, 50.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "810it [00:15, 47.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "816it [00:15, 48.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "822it [00:16, 49.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "828it [00:16, 50.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "834it [00:16, 51.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "840it [00:16, 51.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "846it [00:16, 50.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "852it [00:16, 50.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "858it [00:16, 51.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "864it [00:16, 51.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "870it [00:17, 48.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "875it [00:17, 48.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "881it [00:17, 50.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "887it [00:17, 50.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "893it [00:17, 49.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "898it [00:17, 49.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "904it [00:17, 50.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "910it [00:17, 50.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "916it [00:17, 51.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "922it [00:18, 51.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "928it [00:18, 51.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "934it [00:18, 52.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "940it [00:18, 52.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "946it [00:18, 52.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "952it [00:18, 52.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "958it [00:18, 49.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "964it [00:18, 50.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "970it [00:19, 50.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "976it [00:19, 49.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "981it [00:19, 49.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "987it [00:19, 49.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "993it [00:19, 50.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "999it [00:19, 51.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1005it [00:19, 51.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "1011it [00:19, 51.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "1017it [00:19, 51.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "1023it [00:20, 51.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "1029it [00:20, 51.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "1035it [00:20, 52.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "1041it [00:20, 53.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "1047it [00:20, 52.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "1053it [00:20, 52.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "1059it [00:20, 52.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "1065it [00:20, 52.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "1071it [00:20, 52.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "1077it [00:21, 51.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "1083it [00:21, 51.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "1089it [00:21, 52.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "1095it [00:21, 52.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "1101it [00:21, 53.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "1107it [00:21, 53.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "1113it [00:21, 52.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "1119it [00:21, 52.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "1125it [00:21, 51.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "1131it [00:22, 50.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "1137it [00:22, 50.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "1143it [00:22, 51.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1149it [00:22, 52.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "1155it [00:22, 51.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1161it [00:22, 49.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "1167it [00:22, 50.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "1173it [00:22, 51.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "1179it [00:23, 52.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "1185it [00:23, 52.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "1191it [00:23, 52.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "1197it [00:23, 52.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "1203it [00:23, 51.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "1209it [00:23, 50.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "1215it [00:23, 50.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "1221it [00:23, 51.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "1227it [00:23, 51.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "1233it [00:24, 52.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "1239it [00:24, 51.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "1245it [00:24, 51.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "1251it [00:24, 51.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "1257it [00:24, 51.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "1263it [00:24, 50.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "1269it [00:24, 50.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "1275it [00:24, 50.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "1281it [00:25, 50.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "1287it [00:25, 50.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "1293it [00:25, 51.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "1299it [00:25, 52.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "1305it [00:25, 51.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "1311it [00:25, 51.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "1317it [00:25, 51.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "1323it [00:25, 52.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1329it [00:25, 52.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "1335it [00:26, 52.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "1341it [00:26, 52.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "1347it [00:26, 53.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "1353it [00:26, 53.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "1359it [00:26, 54.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "1365it [00:26, 53.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "1371it [00:26, 53.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "1377it [00:26, 53.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "1383it [00:26, 53.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "1389it [00:27, 52.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "1395it [00:27, 53.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "1401it [00:27, 53.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1407it [00:27, 54.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "1413it [00:27, 52.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "1419it [00:27, 52.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "1425it [00:27, 52.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "1431it [00:27, 52.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1437it [00:27, 53.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "1443it [00:28, 52.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "1449it [00:28, 51.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "1455it [00:28, 51.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "1461it [00:28, 51.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "1467it [00:28, 52.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "1473it [00:28, 52.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "1479it [00:28, 52.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "1485it [00:28, 50.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "1491it [00:29, 51.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "1497it [00:29, 52.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "1503it [00:29, 52.91it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1509it [00:29, 52.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "1515it [00:29, 52.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "1521it [00:29, 52.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "1527it [00:29, 51.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "1533it [00:29, 52.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "1539it [00:29, 51.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "1545it [00:30, 52.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "1551it [00:30, 52.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "1557it [00:30, 51.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "1563it [00:30, 52.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1569it [00:30, 52.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "1575it [00:30, 52.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "1581it [00:30, 52.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "1587it [00:30, 51.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "1593it [00:30, 50.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "1599it [00:31, 50.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "1605it [00:31, 49.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "1610it [00:31, 47.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "1615it [00:31, 46.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "1620it [00:31, 46.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "1625it [00:31, 45.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "1630it [00:31, 44.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "1635it [00:31, 43.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "1641it [00:32, 45.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "1646it [00:32, 45.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "1651it [00:32, 46.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "1657it [00:32, 48.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1663it [00:32, 50.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "1669it [00:32, 50.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "1675it [00:32, 50.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "1681it [00:32, 50.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "1687it [00:32, 48.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "1693it [00:33, 49.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "1699it [00:33, 50.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "1705it [00:33, 50.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "1711it [00:33, 47.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "1716it [00:33, 46.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "1722it [00:33, 47.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "1728it [00:33, 49.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1734it [00:33, 50.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "1740it [00:34, 51.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "1746it [00:34, 51.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "1752it [00:34, 51.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "1758it [00:34, 52.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "1764it [00:34, 51.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "1770it [00:34, 51.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "1776it [00:34, 51.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1782it [00:34, 52.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "1788it [00:34, 50.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "1794it [00:35, 51.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "1800it [00:35, 51.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "1806it [00:35, 52.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "1812it [00:35, 50.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "1818it [00:35, 50.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "1824it [00:35, 50.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "1830it [00:35, 47.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "1835it [00:35, 48.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "1841it [00:36, 49.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "1847it [00:36, 50.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "1853it [00:36, 51.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "1859it [00:36, 48.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "1864it [00:36, 47.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "1869it [00:36, 48.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "1875it [00:36, 48.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "1881it [00:36, 49.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "1887it [00:36, 48.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "1892it [00:37, 47.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "1897it [00:37, 47.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "1903it [00:37, 48.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "1909it [00:37, 49.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "1915it [00:37, 50.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "1921it [00:37, 50.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "1927it [00:37, 50.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "1933it [00:37, 50.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "1939it [00:37, 50.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "1945it [00:38, 51.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "1951it [00:38, 51.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "1957it [00:38, 52.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "1963it [00:38, 51.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "1969it [00:38, 50.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "1975it [00:38, 48.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "1980it [00:38, 48.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "1985it [00:38, 48.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "1991it [00:39, 48.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "1997it [00:39, 49.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "2003it [00:39, 50.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "2009it [00:39, 50.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "2015it [00:39, 50.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "2021it [00:39, 50.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "2027it [00:39, 51.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "2033it [00:39, 50.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "2039it [00:39, 50.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "2045it [00:40, 51.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "2051it [00:40, 52.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "2057it [00:40, 52.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "2063it [00:40, 51.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "2069it [00:40, 52.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "2075it [00:40, 53.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "2081it [00:40, 51.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "2087it [00:40, 49.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "2092it [00:41, 49.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "2098it [00:41, 49.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "2104it [00:41, 50.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "2110it [00:41, 51.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "2116it [00:41, 51.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "2122it [00:41, 48.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "2127it [00:41, 45.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "2132it [00:41, 43.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "2137it [00:41, 42.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "2143it [00:42, 45.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "2148it [00:42, 45.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "2153it [00:42, 46.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "2159it [00:42, 48.00it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-05afbe322ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestsetloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mspec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eval_veri'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-cb02432392bc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mspec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav2spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoice1_path_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mspec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav2spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoice2_path_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-12ec4a146902>\u001b[0m in \u001b[0;36mwav2spectrogram\u001b[0;34m(path, segment_len, window, Tw, Ts, pre_emphasis, alpha, return_onesided)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# spectogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     _, _, spec = signal.spectrogram(samples, rate, window, Nw, Ns, nfft, \n\u001b[0;32m---> 31\u001b[0;31m                                     mode='magnitude', return_onesided=return_onesided)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# just multiplying it by 1600 makes spectrograms in the paper and here \"the same\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36mspectrogram\u001b[0;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode)\u001b[0m\n\u001b[1;32m    705\u001b[0m                                             \u001b[0mnoverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetrend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                                             \u001b[0mreturn_onesided\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                                             mode='stft')\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'magnitude'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36m_spectral_helper\u001b[0;34m(x, y, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode, boundary, padded)\u001b[0m\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[0;31m# Perform the windowed FFTs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fft_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetrend_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msame_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36m_fft_helper\u001b[0;34m(x, win, detrend_func, nperseg, noverlap, nfft, sides)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/fftpack/basic.py\u001b[0m in \u001b[0;36mfft\u001b[0;34m(x, n, axis, overwrite_x)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwork_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test\n",
    "labels_list = []\n",
    "pred_dists_list = []\n",
    "net.eval()\n",
    "\n",
    "for iter_num, (label, spec1, spec2) in tqdm(enumerate(testsetloader)):\n",
    "    label, spec1, spec2 = label.to(DEVICE), spec1.to(DEVICE), spec2.to(DEVICE)\n",
    "    spec1, spec2 = net(spec1, spec2, phase='eval_veri')\n",
    "    dist = F.pairwise_distance(spec1, spec2).item()\n",
    "    \n",
    "    # append a prediction and label to results\n",
    "    labels_list.append(label.item())\n",
    "    pred_dists_list.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.45it/s]\u001b[A\n",
      "2it [00:01,  1.48it/s]\u001b[A\n",
      "3it [00:01,  1.51it/s]\u001b[A\n",
      "4it [00:02,  1.53it/s]\u001b[A\n",
      "5it [00:03,  1.52it/s]\u001b[A\n",
      "6it [00:03,  1.56it/s]\u001b[A\n",
      "7it [00:04,  1.57it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-686d62237bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounterparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainsetloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounterparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounterparts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3065b74e0fd8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# there is no need to keep tensors in GPU memory # TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mpositives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_num in range(EPOCH_NUM):\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # train\n",
    "    net.train()\n",
    "    for iter_num, (labels, anchors, counterparts) in tqdm(enumerate(trainsetloader)):\n",
    "        anchors, counterparts = anchors.squeeze(0), counterparts.squeeze(0)\n",
    "        optimizer.zero_grad()\n",
    "        labels, anchors, counterparts = labels.to(DEVICE), anchors.to(DEVICE), counterparts.to(DEVICE)\n",
    "        anchors, counterparts = net(anchors, counterparts, phase='train_veri')\n",
    "        loss = criterion(labels, anchors, counterparts)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # TBoard\n",
    "        step_num = epoch_num * len(trainsetloader) + iter_num\n",
    "        TBoard.add_scalar('Metrics_verification/train_loss', loss.item(), step_num)\n",
    "        TBoard.add_scalar('Metrics_verification/lr', lr_scheduler.get_lr()[0], step_num)\n",
    "        TBoard.add_scalar('Metrics_verification/conv5', net.conv5.weight.mean(), step_num)\n",
    "        TBoard.add_scalar('Metrics_verification/fc8', net.fc8.weight.mean(), step_num)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "# when the training is finished save the model\n",
    "# torch.save(net.state_dict(), os.path.join(LOG_PATH, 'model_snapshot_{}.txt'.format(time.time())))\n",
    "# TBoard.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cdet(Pmiss, Pfa, Cmiss=1, Ptar=0.01, Cfa=1):\n",
    "    return Cmiss * Pmiss * Ptar + Cfa * Pfa * (1 - Ptar)\n",
    "\n",
    "def Cmin(labels, dists, Cmiss=1, Ptar=0.01, Cfa=1):\n",
    "    \n",
    "    Cdet = Cmiss * Pmiss * Ptar + Cfa * Pfa * (1 - Ptar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
